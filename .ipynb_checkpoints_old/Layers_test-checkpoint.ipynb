{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PARALLEL NOTEBOOK EXAMPLE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import parallel module client**\n",
    "\n",
    "*Either run ipcluster start --profile=profile_name -n 6 (start 6 engine cluster)*\n",
    "\n",
    "*OR*\n",
    "\n",
    "*From notebook home page select clusters and run start from there (default is all cores so select number before you start!!)*\n",
    "\n",
    "Where profile refers to the profile you've used to run this notebook. (profile_default if none selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worker engine IDs: [0, 1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "from IPython.parallel import Client\n",
    "# Tell it what engines to use path to .json file stored in:\n",
    "# ~/.ipython/profile_name/security/ipcontroller-client.json\n",
    "rc = Client('/noc/users/hb1g13/.ipython/profile_thalassa/security/ipcontroller-client.json')\n",
    "# Most simple way of executing in parallel is direct view\n",
    "dview = rc[:]\n",
    "\n",
    "print(\"Worker engine IDs: {}\".format(rc.ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to feed modules and functions to each engline through:\n",
    "\n",
    "**%%px --local**\n",
    "\n",
    "cell magic at top of each cell that's required for all workers\n",
    "\n",
    "you can work out a variable and then pass it on so save memory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%px --local\n",
    "from scipy.io import netcdf\n",
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "import sys\n",
    "import netCDF4\n",
    "from numba import autojit\n",
    "import glob\n",
    "from pylab import *\n",
    "sys.path.append('/noc/users/hb1g13/Python/python_functions/')\n",
    "from useful import *\n",
    "###        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This script is remapping eddy fluxes to grid used by MITgcm Layers package\n",
    "It's a lot of regridding and interpolation so ideal to put in parallel**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%px --local\n",
    "## Generate file structure and list of files to use\n",
    "OP = 'Closeddaynokpp'\n",
    "x = '/noc/msm/scratch/students/hb1g13/Mobilis/'\n",
    "lists = glob.glob(x+'/'+(OP)+'/*alled.nc')\n",
    "###                                                                                                                  \n",
    "# Read in the timeaveraged files                                                                                     \n",
    "print 'Loading Tav and grid fields...'\n",
    "file2 = netCDF4.Dataset(x+'/'+str(OP)+\"/Tav.nc\",'r')\n",
    "file3 = netCDF4.Dataset(x+'/'+str(OP)+\"/grid.nc\",'r')\n",
    "Temp = file2.variables['THETA'][:].squeeze()\n",
    "Yc = file2.variables['Y'][:]\n",
    "X = file2.variables['X'][:]\n",
    "Zp = file3.variables['Zp1'][:]\n",
    "dz = Zp[0:len(Zp)-1]-Zp[1:len(Zp)]\n",
    "Z = file3.variables['Z'][:]\n",
    "V = file2.variables['VVEL'][:].squeeze()\n",
    "Yp1 = file2.variables['Yp1'][:]\n",
    "\n",
    "# Regrid V to center pointsVC = numba_regrid(V[:]*1)                                                                 \n",
    "V = numba_regridy(V)\n",
    "\n",
    "# LAYERS STYLE ITERPOLATION                                                                                          \n",
    "# Split cells into 10                                                                                                \n",
    "FineGridFact = 10\n",
    "ZFF = np.zeros((300))\n",
    "for kk in range(len(Z)-1):\n",
    "    ZFF[10*kk:10*kk+10] = np.linspace(Z[kk],Z[kk+1],10)\n",
    "ZFF[-10::] = np.linspace(Z[-1],Zp[-1],10)\n",
    "\n",
    "TTavff = np.zeros((300,400,200))\n",
    "VTavff = np.zeros((300,401,200))\n",
    "for ii in range(len(X)):\n",
    "    for jj in range(len(Yc)):\n",
    "        TTavff[:,jj,ii]=interp(ZFF,Z[::-1], Temp[::-1,jj,ii])\n",
    "        VTavff[:,jj,ii]=interp(ZFF,Z[::-1], V[::-1,jj,ii])\n",
    "\n",
    "VTavff = numba_regridy(VTavff)\n",
    "# Bin Temps layer                                                                                                    \n",
    "Rho = np.arange(-2,11,0.1)\n",
    "TTavffbin = zeros_like(TTavff)\n",
    "for ii in range(len(X)):\n",
    "    for jj in range(len(Yc)):\n",
    "        for kk in range(len(ZFF)):\n",
    "            TTavffbin[kk,jj,ii] = find_nearest(Rho,TTavff[kk,jj,ii])\n",
    "\n",
    "# Load in each file and find V'T' and timeaverage it!  \n",
    "lists = glob.glob(x+'/'+str(OP)+'/*alled.nc')\n",
    "VTprimetav20 = 0\n",
    "VTbar20 = 0\n",
    "total=len(lists)\n",
    "                                                                         \n",
    "Rho = np.arange(-2,11,0.1)\n",
    "Tpff = np.zeros((10,300,400,200))\n",
    "Vpff = np.zeros((10,300,400,200))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**I'm going to now define a fuction that I want to run in parallel**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%px --local\n",
    "def eddyfluxbin():\n",
    "    '''Its always good to have a docstring\n",
    "       Args = none     \n",
    "       Returns remapped time averaged V'T' and VT\n",
    "    '''\n",
    "    lists = glob.glob(x+'/'+str(OP)+'/*ALLED.nc')\n",
    "    VTprimetav20 = 0\n",
    "    VTbar20 = 0\n",
    "    for file in lists:\n",
    "        file2 = netCDF4.Dataset(file,'r')\n",
    "        Temp = file2.variables['THETA'][:]\n",
    "        V = file2.variables['VVEL'][:]\n",
    "        Vc = numba_regridy(V)\n",
    "        # Split into chunks to make RAM use ~20GB per core\n",
    "        for yr in range((60)):\n",
    "            yr1 = 10*yr\n",
    "            yr2 = yr1+10\n",
    "            Vchnk = Vc[yr1:yr2,:,:,:]\n",
    "            Tchnk = Temp[yr1:yr2,:,:,:]\n",
    "            # Interpolate and bin into 0.1C temp bins as before\n",
    "            for tt in range((10)):\n",
    "                for ii in range(len(X)):\n",
    "                    for jj in range(len(Yc)):\n",
    "                        Tpff[tt,:,jj,ii]= interp(ZFF, Z[::-1], Tchnk[tt,::-1,jj,ii])\n",
    "                        Vpff[tt,:,jj,ii]= interp( ZFF, Z[::-1],Vchnk[tt,::-1,jj,ii])\n",
    "                    for kk in range(len(ZFF)):\n",
    "                        Tpff[tt,kk,jj,ii] = find_nearest(Rho,Tpff[tt,kk,jj,ii])\n",
    "            Vprime = Vpff-VTavff\n",
    "            Tprime = Tpff[:]-TTavffbin[:]\n",
    "            VTprime = Vprime*Tprime\n",
    "            VTprimetav = np.mean(VTprime,axis=0)\n",
    "            VTprimetav20 = (VTprimetav20 + VTprimetav/(60*total))\n",
    "            VTbar = np.mean(Vpff*Tpff,axis=0)\n",
    "            VTbar20 = VTbar20+VTbar/(60*total)\n",
    "    return VTprimetav20, VTbar20\n",
    "# Numba is C wrapper for function\n",
    "# Should see noticable improvement in speed\n",
    "numba_eddyfluxbin = autojit()(eddyfluxbin)\n",
    "numba_eddyfluxbin.func_name = \"eddyfluxbin\"     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PARALLEL EXECUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dview.execute( 'A_local = numba_eddyfluxbin()', block=True)\n",
    "# Gather results\n",
    "A = dview.gather('A_local').get()\n",
    "VTbar20 = (A[1]+A[3]+A[5]+A[7])/4\n",
    "VTprimebar20 = (A[0]+A[2]+A[4]+A[6])/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = netcdf.netcdf_file(x+'/'+str(OP)+'/VTprimebar.nc','w')\n",
    "f.createDimension('X',len(VTprimebar20[1,1,:]))\n",
    "f.createDimension('Y',len(VTprimebar20[1,:,1]))\n",
    "f.createDimension('ZFF',len(VTprimebar20[:,1,1]))\n",
    "VT = f.createVariable('VT','double',('ZFF','Y','X'))\n",
    "VT[:] = VTprimebar20\n",
    "f.close()\n",
    "# Write to nc format                                                                                                 \n",
    "f = netcdf.netcdf_file(x+'/'+str(OP)+'/VTbar.nc','w')\n",
    "f.createDimension('X',len(VTbar20[1,1,:]))\n",
    "f.createDimension('Y',len(VTbar20[1,:,1]))\n",
    "f.createDimension('ZFF',len(VTbar20[:,1,1]))\n",
    "VT = f.createVariable('VT','double',('ZFF','Y','X'))\n",
    "VT[:] = VTbar20\n",
    "f.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
